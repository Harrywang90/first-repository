'''伪装浏览器


HTTP 报文分两种: 请求报文和响应报文，浏览器发送出去的请求报文包括GET

GET的时候添加header两种方法：

第一种： 简便直接，不好扩展功能：'''

import urllib.request
url = 'http://www.baidu.com'
req = urllib.request.Request(url, headers = {'Connection': 'Keep-Alive',
    'Accept': 'text/html, application/xhtml+xml, */*',
    'Accept-Language': 'en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3',
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko'#此处为伪装的浏览器信息}）
    
respo = urllib.request.urlopen(req)
data = respo.read()
print(data.decode('utf-8')

'''第二种方法使用了build_opener方法，定义opener，方便扩展，一下扩展了自动处理Cookies功能'''

import urllib.request
import http.cookiejar

def makeMyopener(head = {'Connection': 'Keep-Alive',
    'Accept': 'text/html, application/xhtml+xml, */*',
    'Accept-Language': 'en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3',
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko'}):
	cj = http.cookiejar.CookieJar()
	opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
	header = []
	for key, value in head.items():
		elem = (key, value)
		header.append(elem)
	opener.addheaders = header
	return opener

opener = makeMyopener()
uop = opener.open('https://0.61803398875.xyz/2017/08/17/good-product.html', timeout =1000)
data = uop.read()
print(data.decode())
